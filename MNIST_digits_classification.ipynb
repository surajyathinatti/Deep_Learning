{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surajyathinatti/Deep_Learning/blob/master/MNIST_digits_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vHrYapBVCBvk",
        "colab_type": "code",
        "outputId": "9eb2bc36-1123-42c6-9141-88d0924904c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "#importing required libraries \n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#to check the tensorflow version\n",
        "tf.__version__\n",
        "\n",
        "#importing the MNIST digits classification dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "#print(mnist)\n",
        "\n",
        "# size of the image\n",
        "size = x_train[0].size \n",
        "#print(size) #size of the image is 784 which is 28 * 28\n",
        "\n",
        "#unpacking the dataset into traing and testing\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data() \n",
        "#print(x_train[100])       \n",
        "\n",
        "\n",
        "\"\"\"\n",
        "1. print(x_train[100]) gives the array of numbers from 0 to 255 i.e RGB \n",
        "   channel values\n",
        "2. to convert these numbers to binary (computer understanding we \n",
        "   normalize/scale the data)\n",
        "\"\"\"\n",
        "\n",
        "#use matplotlib to display the images\n",
        "#plt.imshow(x_train[0])\n",
        "\n",
        "#normalize/scale  the data \n",
        "x_train = tf.keras.utils.normalize(x_train, axis = 1)\n",
        "x_test = tf.keras.utils.normalize(x_test, axis = 1)\n",
        "#print(x_train[0])  #array of numbers are converted between 0 and 1\n",
        "#plt.imshow(x_train[0])\n",
        "\n",
        "#build the model\n",
        "model = tf.keras.models.Sequential()\n",
        "# print(model) #object is created at the memory location 0x7f2a5aa45fd0\n",
        "\"\"\"\n",
        "Two types of models \n",
        "1. Sequential (most common type model)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())  #input layer\n",
        "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu)) #hiddel layer\n",
        "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu)) #hiddel layer\n",
        "model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax)) #output layer\n",
        "\n",
        "\"\"\"\n",
        "creating the input layer, hidden layer and output layer\n",
        "2 hidden layers with 128 neurons and rectified linear unit activation\n",
        "#outputlayer with dense layer and softmax activation\n",
        "\"\"\"\n",
        "\n",
        "#training the model, optimizer always minimizes the loss\n",
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics = ['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=3)\n",
        "\n",
        "#calculate val_loss and val_accuracy\n",
        "val_loss, val_acc = model.evaluate(x_test,y_test)\n",
        "print('Val_Loss: ' + str(val_loss) + ', '+ 'Val_Acc:' + str(val_acc))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.2628 - acc: 0.9233\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.1095 - acc: 0.9665\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0749 - acc: 0.9764\n",
            "10000/10000 [==============================] - 0s 38us/step\n",
            "0.0977474351072684 0.9698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PzK2cwhux3a5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MJIPR1T3CSTa",
        "colab_type": "code",
        "outputId": "d8836cd2-5a85-45c0-c30b-534b7bc9cbb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#calculate val_loss and val_accuracy\n",
        "val_loss, val_acc = model.evaluate(x_test,y_test)\n",
        "print('Val_Loss:' + str(val_loss) +\" \" + 'Val_Acc:'+ str(val_acc))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 31us/step\n",
            "Val_Loss:0.0977474351072684 Val_Acc:0.9698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "16lLRRQhDS-U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}